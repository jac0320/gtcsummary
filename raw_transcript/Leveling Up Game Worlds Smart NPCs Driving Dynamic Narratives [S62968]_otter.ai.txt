0:00
by me, I've been in AI for about seven years and started with distributed training and went all the way to synthetic data for trading robots. I believe there's a lot of overlap between robotics and AI MPCs as you are communicating with a virtual entity that and then we can perform actions and move around the world. And it makes it exciting because now you can orchestrate a set of NPCs in this virtual world and have real time reactions.

0:31
And this is video codec. Such neither was further to the attention.

0:37
Yeah, hi, everyone. Thanks for having me on the panel is great. So kind of like Kyle and I grew up gaming. It's actually what brought me to Nvidia and I put little stickers on my PC and that's really what I've been kind of all about. So passionately gaming has led to leading a bunch of AI products and video and now we're bringing AI into the thing I love. And so you know, looking to bring a lot of kind of traditional gamer knowledge and also our new kind of tech in terms of generative AI to gaming. He's so excited to have this conversation.

1:05
Awesome. So without further ado, let's kick things off by addressing how majestic AI are more specifically and events are enabling that paradigm shift for game characters capabilities. So Caroline, can you tell us a little bit about AI? About inward AI engine and how is it shifting this person and basically crafting the personalities of NPCs?

1:31
Yeah, so I think the thing that we've all kind of seen with Jared Bailey has the capacity to kind of extrapolate from a small amount of information. What we're doing with the engine is basically a layer that lives alongside the game engine. So whether it's unity, unreal, the Web SDK, and basically it's receiving information from the game state so whether those are player actions, you know, things about the environment for specific things that the characters are doing a given moment. And then it basically processes a series of steps we call perception, cognition behavior. So effectively understanding what it's seeing through multimodal input. So vision sound, text button. presses, processing, natural cognitions and understanding of knowledge or tree what to create what emotions intend to recognize, and it passes that through a reasoning step to basically understand what do I do next in terms of verbal and nonverbal behavior, but also directly how do they affect the game state so may not just affect the character behavior itself, but directly affecting the game state and then the cause of that is basically an emergent behavior that is still aligned with the narrative and gameplay, but actually about the magic of you know, the dangers of AI for games is that it kind of has this expansive capacity where it kind of expands the, the kind of scope as possible outcomes to a degree that may kind of derail the core experience to the player. And so it's our job to make sure that the engine kind of maintains that coherence to the actual narrative, and the vision of the directors while still giving the player kind of that sense of of emergent behavior. And so, you know, it may be just a companion who's adapting to, for example, what you're doing and again, what we're finding difficult and giving you those hints in real time, or actually, you know, an enemy who's dynamically having a conversation with you and giving you sort of more intelligent barks depending on your specific level of decisions made and everything else. And the really cool of this is making sure that every choice decision that the player has has a meaningful consequences in the world. That is difficult to basically build that you're doing all that scripting. I mean, most of the I was a huge Polish hmm, actually loved it. And just the depth that Larry went into, though, to get to every one of those different possible outcomes is immense. And I think you know, as especially indie games, even bigger studios as they want to build those bigger worlds, it feels like to deliver that responsiveness to players. We're going to need a next change in technology and I think that's where they actually comes in.

3:43
Grace and approach to this. How do we make sure that NPCs are aware of the mechanics of the game and save money? Other players

3:59
Yeah. So I prefer the emphasis essay on the the desired narrative. I do want them to stay into what we have designed is the narrative design system. So what this enables you to do is to bring back control to that game designer, a game developer, is such that they can follow a narrative. So for example, you want to build a game and you have a dialogue tree that the NPC follows. So that is the previous way that my son, but he was very limiting. But you still want to keep this a staged approach to this, what he's enabled, which in our language models is that now you can instruct throughout the narrative of this game, what the surfaces can do. So for example, you want to start the MVC to in this environment, do something and progress that conversation in this direction yet still be open and that is something that you can do today with our lamps and this is what makes these elements really powerful. Now, as this goes to the virtual world, how this is connected with so now as you walk into a space, and then progress that conversation forward, you can enable this narrative to trigger based on the environment and then produce a coalition required for this space. This enables game designers and game developers to have control over the story while still allowing this open ended nature.

5:42
For a virtuous cycle, how do you think and then responders if they are initiating real time interactions and engagement liberating conscripts and nurses?

5:52
Yeah, that's a that's a big question, right? I mean, so kind of one way we can think about how generative AI is really trying to replicate characters in the nursery important to them. That's right. We're almost like, you know, so it turns out humans are kind of complex. And so we need a bunch of generative models to be able to replicate some of these functions. You know, large language models is kind of what I'm talking about, you know, in versions of those provide a lot of perception and cognition and reasoning. capabilities. But we are looking at linear models to, you know, we can replicate the years with things called ASR. So we take speech and then we turn that speech into text, we use it at bamar for that, and then we need you know, additionally, things like TTS because texts output turns out to also be kind of boring to read. You kind of want to hear that avatar. And so you need that text output, but then give that give that voice live. And then we're gonna see them. We don't know what they're gonna say, as you can see, they gave the animations and so you need other models to be able to to train the face and be able to bring those things to life. And what's cool about that kind of wrapping the faculty the narrative, once you have a realistic avatar that actually opens up a lot of what narrative can do, because if you're reading something and just trying to tell a story, you have to play to the imagination in a certain way. The moment you can have an avatar, they're talking to you it brings that level of light lightness and actually expands the opportunity opportunities of storytelling. So I think really generative AI here is completely transformational to how we're going to tell stories, something to replace, or to add this new element that really hasn't happened yet.

7:24
Wonderful. So you know, we talked in there this time, Jason data is shaping these kinds of ways and interactions. But this comes also with many challenges, right? So let's explore this. The key challenges the NPC interactions, how does your respective platforms get NPCs more autonomy to drive and evolve the storylines based on their interactions? At the same time, because they're giving me a player agency?

7:53
Sure, sure. Yeah. So the way that we think about this is, you know, game designers have always kind of had these kind of critical paths that they want players to follow. And so every I always kind of start with that player vision of like, what do you actually want the players to be experiencing real time and technology, distributed services? And so you know, from day one, we've kind of very early on our partnership in our in our company, we had a partnership with Disney. And that was like trial by fire. Like there are very strict ways that these characters and these experiences are supposed to evolve. Anybody here has ever been a project with Disney when we know this. And so, you know, we very quickly realized that like our job was not to continue expanding sort of scope of gender output, but actually to almost add these like positive constraints on the experience that allow the designer kind of put in their vision. And so I think what the what that's come up with is, you know, it's first of all, how do you kind of build the actual character itself and allowing the right amount of controls such that they can express the personality that you want them to be aligned with? Then it's about the narrative controls that allow them kind of be beholden to the storyline, you know, making sure that the beats are actually in there that the character doesn't know something, for example, until it's triggered, because if the character is loudly information upfront, you know, it's gonna break that but then also we call acknowledged, so making sure that the experience is actually grounded in the knowledge that the user has or that the developer is actually input and is stay true to that hallucinations are really part of the problem in general AI can really break games if you go beyond sort of the scope of that. So we focus a lot of that. And then of course, there's safety and games are built for tons of different audiences. And so how we build that safety and those ethics is is really key. And even if they're mature games, it's certainly topics that you don't want people in there. So I think it's kind of making sure that we are basically building the technology to serve the creative vision. And as we've had these partnerships we've seen that kind of come to life, and they don't we are very honest, we're not a game studio. And so our job is complete. And we work with amazing creative directors and their designers who are actually ones providing this, like there's a great quote from one of our human self partners, who was sharing that, you know, the tools felt like they were built for her and I was very happy to hear that because it feels like that we're doing a good job. You know, we're basically extending the creative capacities of the narrative narrative designers and creative directors, the producers and developers, rather than them being beholden to like, you know, the current capabilities and technology.

10:09
Yeah, what we have discovered recently that I did the signers again, the signers, what they want is to actually be able to evaluate what the NPCs are producing. So for example, you have your knowledge base, you have your backstory, and yes, it's retraining for on that, but to what extent are you wanted to be super tight today versus actually know the rest of the world and be more relatable? So one of the issues that we've seen is that if the sticks only to the knowledge right and only to the backstory, it might create a character that is so fixed, that it is not actually relatable anymore. It's no longer fun to play with because now it's always thinking about that part, same things that are in the backstory or the knowledge bank. So when we give them back is the ability to have a test set based on the positive and negative responses that they are getting. And I by the way, based on that test there NBC and this enables them to experiment and converse with their NPCs as they are making the npc and then ever like, oh, how have my changes and elevator or be evaluated these NPC while you're still while still allowing in for the flexibility that the elements provide because if they say too rigid, then it becomes the same as a dialogue tree right? So then we want to give that flexibility and the only person that can do this is the person who has the world of the mind. Guys, every single studio is going to have a different preference. Like for instance when for us, gi n is unique. They do want to have someone who is a sci fi geek, but to what extent and like not mentioned certain things, of course, because it should expand out a lot. But it should have certain conversation on behaviors that come from that space of knowledge. So these are things that we allow you to test and then deploy into the real world. When you're confident that in your test that it's working in a way that you want to do. So this is something that we returned to the designer.

12:24
So as a follow up question to that, ask him since how do we preserve accuracy? How do we preserve that why guys remain these kinds of characters?

12:35
Yeah, it's no garden really, and kind of safety and stuff. But when you're designing a game, and just I guess, I was saying to write the hallucinations in gaming, like those are actually emergent properties and sometimes, right, that's what gives us some of the creativity that's what unlike some of the other practices were like question answering where you really just don't you know, you don't want your like insurance spot to actually be hallucinating, talking to a customer, not ideal, but in gaming that can be really great if you can actually have that happen and you can tell them interesting story. And so with that actually makes it kind of challenging to guardrail, because when we talk about guardrail, there's a there's a couple different types. There's the safety stuff to kind of talk about even if it's maturity again, there's topics that as a studio you can't go to and so but you want to be able to craft a character that is Miller you know, you want them to you know, be able to swear and be able to do things that you know, generally you might not want to like to check, you can see types of perspective. So it's about customizing those guardrails, giving them their control to people that are creating it on the safety side, so that's one aspect. The other aspect is actually you know, don't break the fourth wall. You are this character if we're playing a game that's like things 1700s If you ask them about politics, or the current president of the United States, you know, they'll be like, I have no idea what you're talking about, and then naturally bring the conversation back to where the story is, where the goal is. And so there's a couple of different technologies that you that you can use to do that. Right. There's like things like girls like we have video that basically analyze the output of the MLM and then try to rescue this super response. But there's other techniques too, by just choosing an appropriate language model that really will just know what is the lore of your story. And so that's where things like develop Facebook today and will be implemented or freight is adding started to add just a wealth of knowledge to that they generally tend to stay on that story. So I don't know if it's a solid science at this point, but I think so far is it's actually turned out pretty successful. And then the demos we've created and use cases we've seen so far, they can pretty much stay on track. I mean, throughout this week, we've had a lot of like press and people coming up to our bridge on your demo, trying to break it sorts of crazy stuff, but it stays on track. So it's great.

14:55
So there are other challenges as we're doing time interactions, especially when we have more time that is a choice. So I want to delve a little bit into that starting with you and I love how can we push the boundaries of what NPCs can do narratively, but also experientially within the game. Yeah.

15:12
So when we're talking with each other, I am expressing myself I will bring my arms I will bring my face I'm likely to watch if you told me to walk and then I'm likely to follow you because that means probably maybe not now. That is what you expect out of our treasure that you're applying to you. So that is why and I have to do it fast. See how awkward it is when there is high latency. So I have to learn super fast. So for that, why we focus on is Image Streaming the voice input into the backend and in the backend we run multiple models concurrently. So one is obviously text to text to give you the right response. But then we are doing the action generation and we focus on complex actions. So if I'm telling you go fetch the jetpack, I expect you to go so the object being the object that bring it to me, and then give it to me, right. So that is a set of four actions. And that requires planning planning is one of the hardest problems in robotics and it's been solved in this simulated environment for these kinds of use cases. So that is our actions pipeline which for action. And then on top of that we need to tell you what emotions is your npc feeling? It gets based on the emotions of the NPC you might want to trigger a behavior right? So if the NPC is feeling nervous or it's feeling happy, it is going to trigger something that the game designer would want. So we're entering that information to the game design it and then on top of that, we have to generate the boys and boys it has to be emotional, that is super important. So we bring these different models together in super low latency that are applied to a player and then the emergent behaviors that are seen in experience is that now for example, in simulation games, you are enabling two people like each other to converse, and then potentially you as a player can just watch or come in and talk to us and then interrupt the relationship so relationships this is gonna be a huge space in which we're going to see a lot more of the experience the improved because space

17:34
awesome. So I would love to hear in words their combat. Yeah,

17:38
so I mean, I think that the, again, starting from the player experience that you've got to think about what the affordances are the learnings of the player as well. And so like as a as a game player, I don't necessarily want to just talk to characters. I want them to be sort of active within the world that I'm in. And so all the different things that add up there. So if you have characters that are stuck in a certain location, it can feel very sort of awkward. Whereas if you're able to do actions while you're speaking, that becomes very important, but still grounding them in the context. So that involves that contextual awareness. So for example, what is in the room, what are the objects available? What are the actual details because objects, then you need the character to be able to do those in concert with the other characters around it. So this essentially we have called the Malteaser director, which effectively takes the context of all the different characters and players in this scenario, and is able to actually direct their actions in concert with one another. As that's true for you know, social dynamics. We don't just do actions independently we do every concert everything else, and then also going just beyond even like the character dialogue and everything. Else, how the world reacts to that. So for example, if a character takes an action, like throws a ball at a bar, it's not just gonna throw a bone bar and smash that bar should actually change you know, the other characters should get up, you know, the maybe there's like a music that plays There's sound effects. And so I think it's really about thinking, you know, our goal is to make an immersive worlds. And what I think immersion means is that dynamic responsiveness to players, and what that means is basically the NPCs need to have the capacity to actually have that effect actually show that real time responsiveness. So the little things they do with their voice, the changes in pitch that they have slightly, you know, the changes in relationships, that is an emotion that can trigger different things. And the interesting thing as well about games is, all of the stuff is cool in the backend, but players don't appreciate it if you don't have those UX elements. And so a lot of that is actually how we expose that internal state to the game developers such that they could build that UX around it. Because one of the biggest things that I think I've learned is, you know, these things don't work. If they're not also in collaboration with the game UX. So for example, how is it shown in the HCT? How is it basically you know, actually integrated into the game mechanics such that these things have consequences. There's a there's a reason to have this conversation as a goal and that conversation, and everything kind of feels like you're moving forward because the players don't feel like they're progressing and they're just standing in a corner and character. And so there needs to be that consequence of the the actions and there also needs to be a responsiveness of the world. And so that won't be the director of contextual awareness action systems, as well as the ability to actually change dynamically, the behavior, the character and the voice. All those things need to be happening, not just like the response to the actual dynamic changes constantly and I think that's really key to giving a player experience. Like

20:12
I think there are things that make the interaction even more immersive. And we've noticed this like firsthand working with partners when we're building digital avatars, whether it is for daily context or non gaming, we noticed that just having a character that looks lifelike is not enough. You want to be able to, for example, nodding their head or act like you're listening, you know, all these nonverbal cues are what make the experience more immersive for players. So looking ahead.

20:45
So there is a ton to be excited about here because now there are like social mechanics that you can unlock. So for example, if you make a player an NPC happy and you can count emotions now, maybe the health of you is trying to reuse less. And it's designers identity, super creative. Like one of the names that we saw made with CommBank was that you had to convince NPCs to free an area and you have to be compelling when doing so. Right. So this is kind of social mechanics, tying it back to the game design, like how does this tie back to animations and like orchestrating these NPCs to the day so for example, Social mechanic that could be arising is you can make one NPC to go convince others to system because they're all out of this environment. And there's so many incredible things that I want you all to be excited. So all of the social mechanical stuff get unlocked. And yeah.

21:43
I think really, we're just starting to scratch the surface on some of the tools and kind of what's been talked about here as we're starting to go like today how the stuff is built, right? It's pretty much a serial chain of model interacts with you when you speak through it. However, kind of what we're touching on here is when we actually start to add agent capabilities to to these instances. You know, I think there's a couple of different stages like right now we're in a conversation, but for most of the demos we've seen, we've started to add some capabilities into it. But as this you know, we get to stage two, which is more like a companion NPCs apology round game scene, but we're really going there's things like autonomous NPCs where, for instance, I could walk up to them, and they can ignore me, because maybe I don't owe money or I'm like, it's not in their best interest to talk to me. And like once you start to have that it really does open up all these different different possibilities. And this is really kind of where this technology is going that and both planning and invoking reasoning that are both building like motivation at that planning cycle. So imagine perceiving the world around you, you have a motivation, like the example I like to use, it's like a lumberjack. If I perceive that I have no more wood and I have no more money, I probably want to develop an action to go do that. And if someone's talking to me at that point, it's probably not in my best interest I can go out. And so like those are kind of the interactions that are going to create these, what we call living worlds. So imagine a city you can walk up as a player, and everybody is kind of walking around having grown intentions in the world. And it gives us this experience that rooflight really never had before.

23:18
And we collaborated with Unity project here at Nexus and that is actually a companion NPC that takes you to our game world and 30 minute gameplay, but basically that cool thing was that it was an emergent behavior. They were very Campisi she was like no I don't want to do that was just funny to watch and this is a big base that we're just going to start seeing. And again, in this case, maybe you want to guard rods that are maybe not and this again goes to their named assignment. Maybe your company and MPC should always be submissive and I probably do, but maybe not. Maybe that's where you just lost her again. She doesn't want to keep rockin because maybe win her back. I don't know.

24:05
So looking ahead, I would like to know each of your perspective on how driven MVC is with impacts of the ability and the infinite gameplay possibilities. of open narrative games.

24:18
Yeah, I think a lot of it is also how we as a collective industry, and like not as just technologists, but we got to find those use cases that are not going to dynamic. I'm really excited, for example, for people to find completely new genres of games. I think that's one big bucket, right? So there's, for example, the social simulation thing that we've been talking about here, which is the actual core mechanic changes. And the interesting thing about this is you know, games have basically been like a jump and shoot mechanic for a very long time. Jump and Shoot happens last year. If you're on your on your MMO RPG, you've got your different actions that you can take. But now we're only going to do mechanics, so there's no mechanics don't need to just be conversational. I think that's the key thing. I as a player, for example, I don't actually like to talk a lot when I'm playing a game. So how could this MVC sort of dynamically change? How can the choices that I make the map to a button press to still allow for gender behavior? All of those I think are still possible in this new genre of game that might be social simulation game. We have another partner for example, who is building a game where the actual game is on your phone, you're having these FaceTime calls, and then they basically give you missions and there's little mini games you can play in between the conversations and it's basically living on almost like a, an interactive movie in real time. So there's a lot of things on the new genre, but what I think is also like you know, for most people in the room, if you're a developer, you know if you're working with game developers, we also found those use cases that are really feasible today. A lot of this stuff is really cool. But if you look at the standard simulation papers, 1.2 and they think about AI in games, it's like $1,000 day run, which I don't think anyone here have had, you know, monetize it. They use it that well. And so I think we need to find those use cases such as the intelligent companions, such as their difficulties systems, those small contained use cases that don't require that dramatic change in game design, and allows for for example, modern DLCs much sooner to test out that player behavior. And and I think they're, you know, there's there's a lot that we're seeing, you know, for example, how can you plan out with a character using multimodal input, the strategy here to take the game and then actually affect the strategy of the character? You know, how can you basically go into a mission, have a character in real time seeing what you're doing and responding so for example, like, there's an enemy to the right, you know, check that out. Oh, I can't get it. Can you get it for me? Like those things that we're used to doing with other players in multiplayer games, or those things that players are used to? Those are the things that I think we really need to focus on as an industry first, before we kind of try and push it because I think the reality is that you know, there's an economic story behind that as well and how we figure that out how we figure out what the running device, I think those will kind of change, but I can work and I think there will be a genre of games that are first to market. And I think as you can see, I'd say a six to eight month period right now that indie games can basically be the first to market with that new genre of AI native games, and I didn't triple A's will be starting with those sort of like more contained experiences. And I'm excited to see I guess, you know, where it would play the obvious things chatbots and talking characters, but like, Where does the AI sort of start to impact the experience beyond that, in a way to me as a player when you don't feel like the world has been more responsive to me and I, I think it always comes back to that which is like, what would I want to play literally like I I crushed it, it's like weekly but I remember very sensitive topic of the game, because I'm good. I want to play it and so that's really always the bar is like what I spent, you know, my entire weekend playing Stan and I probably wouldn't have mental time talking to a character so I got to think more deeply around what were those key mechanics be that would make me want to come back that is a companion that's actually come into play. By playing with my brother and I find the fancy good middle whatever it is. That's I think

27:41
just to like our on top of that because it's it trails in perfectly you know, like one of the one of the harder problems and why a lot of developers can't take risks today because games have this almost like language like your your gamer can pretty much pick up a game and like you get all the cues pretty quickly. And so going outside of those queues is pretty risky. So that's why the enemies are gonna get there. But I think where this type of use case will be really helpful is actually helping with like the tutorial phase. And so like if you've ever like picked up a new game and you have like your buddies on Discord, constantly asked him questions like what I do here, when I do this, how do I do that. And so it's not something where the game designer is to completely redesign it around. But you can add and start to solve the problem by having kind of a conversational tutorial. But that also then enables developers to take a little bit more risk on the type of game that they're going to create. Because now you have somebody that you can, you know, ask questions about talk to and you can add some like really novel new game mechanics, and then have something there and be able to help the player actually understand those and teach them how to play something that they've really never seen before.

28:42
At that point, I will launch with Second Life and it's live everyone can go and use it anytime onboarding bond as well as we are being more and more boss. But the idea is that it has a whole FAQ and every question that you could ever ask. And now you're completely on board than into the spiritual world immediately. And on top of that, it shows you what are the worlds that already saved on my end it can take you between one world to the other and the other. Pilots point it is true it has a decent grade way of today going is onboarding players into this massive world. So there are so many games that we love playing that are multiplayer. Sometimes you just don't have the friends and you don't have time to go when you say to people who is not in your friend group. Maybe they're an NPC will do the trick. Or maybe they're a given like a very large disk or group the guy join. So this is where it makes a lot of power to just like trigger the engagement of your audience and more than seamlessly to these platform. On another note, it's going to back to other games that are planning to play. We like I played so much scenes rollercoasters and all of these things were already infinite right as you know, and I think that way being exciting is that every time is was different right? So now, Iverson i wish i My sense, we don't have some conversation but I could have like watched it and had this half moving half gameplay world that now is more interesting to me with the characters I made. And now they seem to have come to light. Immersing new within these new gameplay such as for instance our godmode here so the AI NPCs are like in the environment and then you as a player come in and influence their behavior and they may follow what you say. Or they may have agency and you can play online with that concept or we are living in a simulation. We have agency on that. But you see there are so many exciting areas that yes, I do not like these massive like cars and NPCs and become super expensive like rather small like to NPCs and then create this campaign and opportunities that engage both female and male audiences. So I think here is an opportunity to potentially being more female gamers.

31:14
There's a really important point which is that a lot of the existing game mechanics that we have today appeal to a certain demographic because the genre shoot slash teenage boys love that. Like there's a there's a and the reality is though I think it's really important that like as a as a sector focused on gaming, we think about how can games actually resonate with more audiences and social dynamics are something that appeal I think, to a broader compared to a more diverse demographic. I think that's really key. Another thing that I wanted to add on to that is, you know, we're talking a lot about here, I think like human to AI interactions. But you know, the beauty of games is also how it brings together people like that talk to people that worked at was there ever like people got married off of flowers? Like that's, that's crazy. A lot of people actually, you know, there's like people who have developed really meaningful relationship became a thing. There's something as well which is like I don't necessarily want AI to detract from that social nature pains and actually take away from the human human experience. So how for example, like I would just push through to the audience and like I've seen it a few really amazing experiences that do this, but like how can we use AI to actually bridge more new human connections? So for example, if we have a shared experience of two NPCs that I won't say you know, again, definitely are playing game together. And it's a really funny experience NPC that becomes something that we can talk about when you go to school or college or y'all work together the next day. And so I think there's something interesting there, which is like how can we use AI to actually push that social and passenger case further rather than detract from it? And I'm really excited for that type of new genre because it because it leads into a games already do well, and I have a pretty new experience that people share. And that's I think one of the reasons that people consume media games is to have a shared experience.

32:47
I just wanted the story of yesterday, I left my computer with a gun lock on running, and then I found three people. I think we all dream fighting that same broad three people to connect with each other here. We just got Mr. Fighting with the NPC telling them that they were better at jujitsu that they needed. So this brought the crowd together.

33:15
I love that story. But building up a little bit of what Kyle was just saying, right, a lot of the technologies we invest in to make good AI PCs also do things like NMT or basically neural machine translation. So if we want to be able to tax people, right, like one of the one of the key areas that will invest into and especially for game developers is connecting those people like over here like I you know, when I play multiplayer games in, like, in North America, pretty much everyone speaks English, but like I'll go over to Europe every now and then I'm gonna be Counter Strike player and you go into the lobby and you'll have five different people speaking five different languages can you be able to communicate? And so I think that's one area where like generative eyes, can we really be able to help with real time translation being able to connect people and even not just language, but we can do this through animation to you know, culturally different, you know, body language that like, you know, there are ways you can animate character to, we can use that same technology not necessarily to drive an AI NPC but you're actually driving the players avatar as well and doing these type of translations that we're going to be investing in for this type of use case but ultimately want to connect with people in a way that I think we all that's one of the things I think we all love most about

34:26
that surgery. So what am I learning later on? It's probably not as developed by my body news today. But I mean, I played online games as a child. I definitely faced a huge language barrier and that is why like with AI emphases today within convey you can speak with NPCs up to four languages concurrently, so I couldn't be speaking to this NPC in Spanish and another person in English and it wouldn't be able to reply. And to me, that's mind boggling. Like that was completely impossible, like a couple years ago, and imagine where this is going to go and it's like a translation. And enabler totally in the future. And yeah, we're talking about gaming news by now. But like, there's so many other use cases, it seems like this corporate marketing application and so on. So say

35:19
we're almost out of time before we wrap up. I was like two minutes so what are you most excited about?

35:25
Looking forward?

35:28
I'm I don't want to get on the soapbox because I am very excited. I think we're seeing how this actually creates like this nucleus where, like, the reason why I started an emerald and why I think this is compelling is games and media have generally always been something that people consume. They've created or created a book, a movie, a TV show, even games are sort of you know, they still follow the kind of report and I think that you know, the magic of what we see with kids doing things in Roblox and Minecraft and Lego is their ability to actually craft the world themselves to actually step into a world of co creative experience. And I think we're, what we're doing here kind of in the merging of AI and gaming is creating a new type experience where the consumer is not consuming the media, but co creating really creative jobs basically to set down the foundations for what that experience is and then for the audience of a player to step into that world and actually prosthetics. And so you know, we have to do hard work to make sure they have the AI controls in there to allow those experiences. The games are hard to control. So what does it actually mean when a world that is still pitching say so we're into a narrative? And I think we're starting to see the you know, the early signs of that, like, like we said, it's not even like interactive games are ads that people actually step into and how to roll in for me was like reading a blank page. No me stepping into, you know, my favorite show or like, I watch my favorite real creative reality TV show. I watch a remarkable amount of I could for example, be able to understand like, like actually popular characters after having experienced there where it doesn't feel I'm just consuming something to taking part in co creation. that full experience is an ability, for example, in games, of course, to have these onboarding characters, but also trying to think about how the world generally dynamically changes. You know, we've seen already like we have games where it's not just detecting like what the user says, but it's actually mapping a complex game state to a triggered the AI such that the actual world is dynamic and kind of adapting to those unique games, say for one library or show that the player is failing to jump over certain legend and reacts to that, you know, it's understanding all those different things. And, and what where I think is goes the next few years is that games and AI come together. And I think already games are kind of influencing movies and TV and everything else, to kind of show what the next generation of media looks like overall, which I think is also like a transformative change. Basically, since people create a media overall, something that is the audience is CO creating what the actual end experience or result is. When you read a newspaper and read a book. It feels like I'm beholden to the story that the narrator The narrator, put down and so I'm super excited, both of our designs for developers in terms of like the next range of experiences, but also collectively, we're all here, you know, game builders to build fun for the people. And to build, you know, things that actually feel different sort of in addition to their life. And that's, that's what I'm really excited to see.

38:14
So short time, I'm extremely excited to see what people create, like, whenever there is any innovation point, creativity is completely unlocked. So now you can create all of these new experiences we've discovered and so many more. So I'm terribly excited to just see why people are creating and like witness it, and help you guys make it right as much as I as we're seeing as developers and designers. All of you are the ones that are going to be making responsible and basically why I'm terribly excited for that. Yeah, talk to me about but on my long term. I'm so excited as to why these names are like human computer interaction, because I think this is completely going to reshape how we interface with computers. I am pretty tired of my laptop. And I wish that there was some kind of new interface and I do think something that feels more conversational, more human and I can give a talk and assigning tasks is going to be valuable for society. And it's going to bring just a new set of experiences all together. And eventually if we're able to control these well in simulations in games were able to measure really say that are performing the way that we want to to the spread Commons of robotics, which is an area that I'm terribly excited about. But in the very short term, already constantly experienced design designers are already building them and this will help you. Yeah, well, I mean,

39:55
I'm excited because this is this is truly an inflection. If we think about you know, I've been a gamer for a long time that in the games industry, we've had technologies that have like made changes to games, and it's like changed the game industry. And they were maybe five to 10% as well as what you can do today. And the different use cases, the agencies or whatever, but you know, we talked about translation, and the use cases go on and on. Again, we're at the tip of the iceberg right now about how this is going to change. You know, in 235 years, I think the entire industry is going to be extremely different based on what Jenai can do for us, because it's going to allow any developers to actually have these grandiose visions. So I've made friends that are that are indie developers, and when he goes out to market, there's blood, sweat and tears in this into this thing. It's 5% of the vision that they want, right? They their ideas are so much bigger than what can be created. And, you know, with tomorrow's capabilities, we can start to see those visions, which is just going to mean all the creativity that we have all these millions of gamers are going to start to become a reality. And so that's really what I'm excited for is I'm really excited to see where this new brand new innovation and technology is gonna take the entire gaming industry and as a gamer, I can't wait to play all those games. It's gonna be great. Wonderful.

41:16
I think we have two minutes. Maybe we can take one or two questions. From the audience if anyone has a question.

41:30
Green light plays like a local hub and

Transcribed by https://otter.ai