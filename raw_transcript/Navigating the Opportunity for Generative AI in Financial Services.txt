 We have a very accomplished panel and I'd like to do a brief introduction.
 So, we'll start with ladies. We have Belinda Neal with Goldman Sachs.
 She's the Chief Operating Officer for Core Engineering and Head of Engineering Partnerships at Goldman Sachs.
 Let's give her a warm welcome. We also have Prem Madrigan from Capital One.
 He's an Executive Vice President, Chief Scientist, and Head of their Enterprise AI.
 Prem was here Monday, he left East Tuesday and came back after BWU on Wednesday.
 So, this is a new expert. And then lastly, not lastly, but we also have Rohi Chauhan.
 Rohi is the Executive Vice President of Artificial Intelligence at MasterCardina National.
 Thank you so much for coming out early.
 And to help guide this conversation, we have our very own Belinda Hall,
 who's a Senior Solution Architect, Data Scientist and PhD.
 This is such an amazing panel that we've put together.
 Really pay attention and hopefully we'll have some time at the end for questions and answers.
 So, with that, take your leave.
 Thank you all for joining us today.
 So, I've had the luxury to spend a little bit of time with these amazing individuals this weekend
 and I'm excited to let them share their thoughts on gents.ai.
 So, the first thing I have, you know, we've all had that iPhone moment, that's what we're calling it, right?
 But I want to know, you know, what led the organization to start investing in gents.ai?
 Belinda, would you care to start us off there?
 That's great, thanks for being here. And what a great week we've had so far and much more to come.
 But I think everyone's been captivated by this new wave of AI.
 At Goldman Sachs, we've been doing AI machine learning for many, many years and built some really great foundations.
 So, when Generative AI showed up on our doorstep and the large language models came,
 you know, we kind of used those foundations to really start to think about how we could get real benefit from this new technology
 that was really being embraced across the world and really captured everyone's hearts and minds
 around how we could really unlock knowledge and things like code in really unique and different ways.
 So, as we got started, you know, I think part of the journey for us was really to capture our business leaders,
 our engineers, to start to think about how we can start to unlock value around these cases
 that were going to really add value to our organization.
 And so, you know, we started with, you know, sharing knowledge and bringing different forms together internally
 and really a governance-first approach in terms of building on some of the foundation
 and one of the most management practices that we really have in place.
 And so, you know, 2023 was definitely a year of innovation and testing and piloting, as I'm sure you've seen and heard
 from various organizations and, you know, really just started to see their really early innings
 of this new technology and where we can capture benefit.
 So, we're just at the start, but we're very excited and we really do see this as a disruptive
 and sustaining technology innovation that we really want to drive into.
 Nice. Thank you. Thank you for saying that.
 Supreme, tell us how to continue.
 How do you do? First, thanks for hosting us here. Thank you for a very nice introduction.
 Malcolm, I have no idea you want to spill the beans on that.
 I don't. I don't. But, you know, one way of looking at all of this is that disruptive as general AI is,
 it is part of a continuum, right? AI has been evolving at times in kind of a smooth kind of world.
 At times, in a step function, right?
 It just happens that this particular step function is the type of step that is based on the 12 step.
 But, so what, you know, when you say why do you invest, you try to see some differentiated business advantage
 or some differentiated customer advantage that you can deliver to your end users.
 What takes you there? I think the first foundation for all of our differentiation comes from data.
 So the reason, so the first reason we invested in this is we have the customers who would benefit from it.
 So we invested in it. The second reason we invested in it now, or we are investing in it now,
 is because we have the data that we can leverage to deliver the value to the customers who can benefit from it now.
 The third reason we invested is because we went all in on the cloud several years ago.
 So all of our data is on a single public cloud, which puts it right next to the compute that we need
 to leverage the data to create the differentiation that delivers the value to the customers who can benefit from it now, right?
 So this whole story, and we have been investing in machine learning for the longest time.
 We've gone through these waves, as you know. People like to call themselves AI people a few decades ago.
 Then in the 90s and early 2000s we went out of our way and decided I don't do AI, I do machine learning.
 And now everybody's doing AI even though they're doing machine learning.
 So there is this continuum, and so our investments have been kind of grown with the value that we see that we can deliver to our customers.
 And we now are pretty excited about the tremendous value that we think we can deliver to customers with this and that kind of shape of decision-making process.
 That's great to hear that journey. In that respect, as you went through that roadmap, I kind of thought about the Terminator.
 I'm dating myself, but that was the first instance of AI that got me interested, you know, a long time ago.
 So let's go to you. Let's talk about what led your organization to invest in Terminator.
 How did you prioritize the use cases, whether to invest in customer experience, new technologies, or productivity?
 First of all, AI is not new to MasterCard. MasterCard's AI journey started sometime in 2006, 2007.
 And then being in the financial industry, we are digitalized by definition.
 So we have an enormous amount of data. And then fraud was the only major use case where the majority of the investment were kind of channels.
 But over time, the technology has progressed, infrastructure has progressed, and a whole bunch of other use cases have now begun to find time.
 I just wanted to kind of mention, you know, pivot on one thing that Green mentioned.
 That if I fast-powered, like, 50 years, 20, 30, 50 years, whatever you want to say, everything will pick up on time.
 Technology, algorithms, everything. The only differentiation is going to be your data.
 And any company sitting on their data has to figure out how you pick up the data and extract value so that you can drive it.
 And MasterCard has been kind of on that journey to sit on a really good day to see over a billion transactions and then figuring out how we can leverage those transactions to extract value.
 So they're part of a whole bunch of use cases. And they are use cases spanning people creating value, consuming experience, and the entire kind of stuff.
 No, that's great. That's great. So now we know how you all got started.
 So now that you have the experience, we're a little over a year or so in, how did you, you know, what part of this AI has been beneficial to your company?
 Sure. So while Gen.AI has suddenly become, has come center stage, Gen.AI is not new.
 And we have been using Gen.AI for quite a few years. Gen.AI is bigger than just GPT and NLMs.
 And we have been using, you know, methods to create some data, to do a whole slew of things over an extended period of time.
 But it is true that the Transformer model is coming into the picture, that NLMs are suddenly becoming available, you know, from the open source community.
 And that a whole slew of business cases, which are off limit, suddenly became addressable.
 And it has just opened up front gates of new opportunities, which will mitigate the kinds of issues that we've had in the past.
 Absolutely. But Belinda, what about you?
 Yeah, great question. I think, you know, people initially have been thinking about some of the efficiency use cases and the productivity use cases,
 which I think people have seen some initial value from and really kind of keen to see results from this new technology in a quite quick fashion.
 But I'd say we also have to think quite thoughtfully about what's going to be strategic to our firm.
 And, you know, as we've just said, how can we leverage the benefits of the organization that we have in terms of our knowledge base to really drive better products and services to our clients.
 So the way we've kind of been capturing our use cases is really being across three different pillars.
 The first is really about how do we enhance our business and kind of drive a great client experience.
 And this is leveraging our data, leveraging our client-facing professionals and really giving them AI tools and really complement and give them access to things that previously were hard to do or more achievable.
 So, you know, we're thinking very thoughtfully how we start augmenting and creating productivity, enhancing tools for our professionals.
 The second really is the developers. I'd say this is a developer conference, firstly.
 But, you know, I think the developers are definitely seeing early benefit from some of the developer co-files that, you know, many people are now using and starting to benefit from.
 But even that's still just fracturing the surface of where the value of generating AI can unlock code.
 Because in the same way large language models can interpret knowledge and insights in language, it can do it in the same way with code.
 And so if you start translating that across an enterprise, you have things like co-generation, but you also have things like coding best practices.
 And in life, legacy, how do we really create a great developer experience for our team?
 And so the developer thread for us is really to get us back to the primitives of developer experience, developer efficiency, and starting to think about what are the metrics that matter?
 How do we unlock the value? How do we create the best environment for developers to do their best work? All this acts.
 So we've been very focused on that at our CIO, Marco Genti, certainly being at the forefront of really driving innovation in that space.
 And then, thirdly, really operating, increasing operational effectiveness.
 I think we're only still early on this journey, but thinking about how AI can unlock processes or workflows that have been traditionally human intensive or labor intensive or time intensive.
 And so how can these new models create a reasoning engine for us to be able to do automation effectively?
 And so that really is a large opportunity for enterprises.
 But also it creates a more interesting role for the person who's working on different tasks across our organization.
 So we're really looking at ways, and generative agents are one thing, where people start early days looking out.
 But I'd say the efficiency operating workflow piece is still early in its journey.
 But I think it shows a lot of promise as ways that we can kind of create a better client experience and also more effective ways that our team can work across different functions.
 Nice. Great. No, that's great. We're going to take time to let developers out in just a second.
 I'm happy to share that. Watching Jensen's keynote, I said to some of my friends, I'm actually at a technical conference.
 This is awesome. So I'm going to get just slightly technical in the spirit of the thing.
 We like talking about it as generative AI.
 The underlying technologies, whether it's deep learning or whatever, they all come together in a particular architecture, which we like to call transformers.
 The thing that transformers have done for us is allow us to consume massive amounts of data with massive amounts of context and learn from that data.
 It turns out one of the most engaging demos that everybody saw was chatGPD that happened to use that thing and consume massive amounts of text data,
 learn lots of relationships between different text tokens and different hierarchical levels.
 And we saw our eyes opened up to the magic, our minds opened up to the possibility of magic.
 Maybe they opened up to more than the magic might have earned, but it's just like the engaging power of language.
 So I think 2023 has been largely about taking a very thoughtful, responsible approach to exploring what are the different things we can do with this.
 Any technology that's potentially discapable deserves kind of a thoughtful approach. Let me understand the limits of these things.
 So many of the use cases we have put it through, some will be in production, but many of them are offline because we're trying to understand the shape of the possibilities here.
 So 2023 has very much been a test and learn kind of thing. Some of those tests, when we feel the risks are low enough and the value to the customers are high enough
 and that we can appropriately mitigate the risk, we've done production experiments, right, or production views.
 But in most cases, it's a thoughtful slope in of getting ready, right, of how can we use all of this data to put it out.
 And there are some interesting learnings there. But more importantly though, I think culturally, capital one, I think this might be true of the industry,
 but we're very much built on a culture of collaboration. And one of the incredible things about gendered AI is the resources required,
 whether it's the talent or the compute or you name it, are not so abundant as to have everybody go off and do their own thing.
 So it's created this natural mobilization of the company of people building on the collaboration culture, wanting to come together to make things happen.
 And that's, to me, that's been magical to watch too, like the culture leading into its trends to come together and do kind of harvest of value, of course.
 No, that's great. You know, as we talk about developers, you know, machine learning leaders, data scientists,
 and everything that you all just mentioned just makes me wonder about some of the challenges.
 You know, we know that it's not easy and, you know, you have thousands and millions of users.
 So what are some of the challenges that you face, you know, when you're trying to scale up for gendered AI?
 So I'll give you a couple of things that are kind of, you know, the long hold of the tent at this point.
 So first of all, you know, kind of leading the transformation or kind of integration of AI within every architecture aspect, you know, has been quite a journey.
 Number one. Number two is that most, you know, of the learnings, the key learnings that came out, you know, from our journey,
 is that rather than taking moon charts and then trying to do everything that we have never been able to do,
 let's figure out all the things that we currently do and figure out how to do it best.
 With that, it has been absolutely incredible because there are things that we can get done so quickly rather than take moon charts of like five years later,
 we're going to have this and unveil this new Ferrari or whatever the case might be.
 In the process, like our team has all the AI expertise. We don't have the domain expertise at all.
 If you're controlling AI within, say, technology redundancies and so on and so forth, we have to collaborate with the teams across the organization
 because they have the domain knowledge and making them feel comfortable working with us.
 Because if you don't educate them enough, AI can very quickly turn into a monster and they don't want to deal with it.
 They want their legs to go through the brake pedal very, very quickly.
 So, you have to figure out how you spend the time making them comfortable and just taking the big steps and getting the organization to move on.
 That's one place which can be challenging and you can invest a whole lot of time.
 The second place which seems to be the biggest or another big challenge is that building the AI algorithm is not the longest-running attempt.
 You have the data. You have the expertise. You can tell that.
 Deploying it is another really, really big challenge.
 You can build AI algorithms within a couple of weeks, but deploying it into production is not trivial.
 That means a massive amount of investment, collaboration, integration with other applications, that cannot be done.
 I know someone that can help you.
 Those are all key. You mentioned something that I really want to touch on next, but whether to build it by.
 We're going to go to that, but before we go there, I want to get to your opinion here on some of the challenges.
 Thank you. A couple of things.
 Many of the cultural challenges are all truth.
 But going back to data, I think even organizations that have invested a lot in data, the way you have to prepare data to maximize the value from this new technology.
 It all depends, but again, what Jen said clearly gave an impression on me.
 He said the way I think about the GPU is this whole thing. It's not that chill.
 The way I think about the AI is not just the algorithm. It's the whole stack.
 When I think about it, the strength of that stack is in the data that you have, the differentiation is in the data that you have.
 The weakness is also right there. It's the quality of the data that you have, the completeness of the data that you have, its readiness to be used as a big process.
 Is it aligned properly? I don't mean AI alignment. I'm just saying the data is aligned properly.
 And that's one thing as I opened up all these new use cases, we're looking at what do we need to do to this data?
 And moving data around is near cheap, not quick.
 And so I think that takes time. The second is scalability of everything.
 Highly regulated industry, appropriately so, because so many of our lives depend on what this industry does.
 So at the same time though, those regulations mean you have to create new scalability of how you identify and manage this.
 But also efficiency, so scaling from the perspective of efficiency.
 And that efficiency is both for computer sources, for talent resources.
 So I think the first time I feel like AI is in a place where almost only an enterprise strategy makes sense.
 A retail fragmented strategy does not make sense.
 And so that's like kind of a transformation too. And that's something people have to get their minds around.
 You mentioned emphasizing a highly regulated industry.
 So before joining video, I also worked in exercise. So that leads to that part.
 But now that brings us to the question that I'm sure we have, how do you storage or practicing safe and responsible AI?
 Belinda, would you care to enlighten us?
 Yeah, that's a great question. And I think it really does start with having central governance around how as an organization you're thinking about deploying large language models.
 Because there are speeches and bugs with this new technology that we have to be very careful about in terms of thinking about how to really balance the risks.
 And again, it comes back to where you're deploying the technology, which use cases internally facing and externally facing.
 And just being very thoughtful about where you can start and safely innovate.
 But then as you say, going to scales is another question and being thoughtful around the risks and the controls that are put in place is really important.
 But going back to another comment as well, I'd say now is the time for enterprises to really be clear on what their strategy is.
 How can you align your organizations and teams on deploying your resources to the most highest impact use cases or areas across your organization and have every part of your firm aligned on where you're targeting.
 So everything from end business users who really have the fence of really understanding where the value can be generated, the specific role and responsibility which they represent.
 And then across our legal and compliance functions for engineering teams.
 So I think there is a really good opportunity from a strategic perspective to align teams across the firm.
 But then also that then unlocks it from a governance perspective.
 The other thing we've done at Goldman Sachs quite early is actually really create a foundational AI platform that really gives us scale and growth to how we're deploying AI.
 And so I think investing in that team and really thinking about how we can do things well once centrally and then be able to scale like a common-spoke approach.
 It's definitely allowed us to think fully about how we govern launch language models in our environment.
 That's great, that's great.
 You know, I think that as an industry, as a community, it will have to fiddle to kind of set the standards and best practices for the regulations.
 So it's great to hear that you're thoughtful about that.
 What about you, Mr. Carr? So, I mean, it's been highly regulated, having strong governance.
 But I think one of the reasons why it is an important topic.
 So in the era of AI, what exactly happened?
 What happened was that the cost of prediction went down to zero.
 You can take any data set and actually create a predictive model.
 And then predictive model is just kind of really intelligent.
 The temptation to create AI models is so high because it's so easy to do it.
 People, without having any malicious intent, may end up using data sets which may not be very grounded.
 And as a result, you're just holding, you're just scaling inefficiencies of the data.
 And I think that is a really, really serious kind of topic.
 And hence, at MasterCard, we take governance extremely, extremely seriously.
 And I believe that we have a standardized, centralized governance committee that actually will review not only the output, but also how the data was sourced,
 what was done on each data set before any other actual production. And even post-production, we need to monitor it to see the threats and so on and so forth, so that we know that we are deviating too much from the scenario under which the models are done.
 Yes, that's great. So Frank, what about you? What are your thoughts and practices for responsible AI?
 I'll say, especially when it comes to Gen.AI, even having been in the AI view for some time, one way or another, I think the first thing is intellectual humility,
 in that I don't think collectively the community has adequate intuition about the shape of some of these things.
 And this is why 2023 has been very explicitly a test-and-null phase for us. And let me continue. The test-and-null vector will continue for many years.
 And so the notion that, look, this was a technology that was designed for something and then showed properties that it was not designed to exhibit.
 This is why people started using this phrase, "emergent behavior." What they really mean is, "My God, I'm surprised that you can do this." But emergent behavior sounds nice because it's commercial.
 And so the second thing is strategic patience. So first is humility. We really need to invest in understanding this thing properly and use it where we can be understanding of the mitigators properly.
 The second is strategic patience, that the gains are so fundamental that there is no urgency to harness them today or tomorrow.
 You want to harness them when you can do so responsibly properly, at least convince yourself that you're being responsible as a first step.
 So to me, the two underlying attitude shifts are actually really channel your intellectual abilities and have strategic patience.
